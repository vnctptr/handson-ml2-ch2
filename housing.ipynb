{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ffe32759",
   "metadata": {},
   "source": [
    "## Data Collection and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdc2a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3bae23",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1004ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_housing_data(\n",
    "    housing_url=HOUSING_URL, \n",
    "    housing_path=HOUSING_PATH\n",
    "    ):\n",
    "    \n",
    "    if not os.path.isdir(housing_path):\n",
    "        os.makedirs(housing_path)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()\n",
    "    \n",
    "fetch_housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7774780e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c2f2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = load_housing_data()\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fffafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75edca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2291592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(data, test_ratio):\n",
    "    shuffled_indices = np.random.permutation(len(data))\n",
    "    test_set_size = int(len(data) * test_ratio)\n",
    "    test_indices = shuffled_indices[:test_set_size]\n",
    "    train_indices = shuffled_indices[test_set_size:]\n",
    "    return data.iloc[train_indices], data.iloc[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4011daf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = split_train_test(housing, 0.2)\n",
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ecb262",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e82f1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zlib import crc32\n",
    "def test_set_check(identifier, test_ratio):\n",
    "    return crc32(np.int64(identifier)) & 0xffffffff < test_ratio * 2**32\n",
    "\n",
    "def split_train_test_by_id(data, test_ratio, id_column):\n",
    "    ids = data[id_column]\n",
    "    in_test_set = ids.apply(lambda id_: test_set_check(id_, test_ratio))\n",
    "    return data.loc[~in_test_set], data.loc[in_test_set]\n",
    "\n",
    "housing_with_id = housing.reset_index() # adds an `index` column\n",
    "train_set, test_set = split_train_test_by_id(housing_with_id, 0.2, \"index\")\n",
    "housing_with_id[\"id\"] = housing[\"longitude\"] * 1000 + housing[\"latitude\"]\n",
    "train_set, test_set = split_train_test_by_id(housing_with_id, 0.2, \"id\")\n",
    "test_set.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe44310",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"income_cat\"] = pd.cut(housing[\"median_income\"], \n",
    "                               bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
    "                              labels=[1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658619aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"income_cat\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e813a90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1)\n",
    "\n",
    "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    strat_test_set = housing.loc[test_index]\n",
    "    \n",
    "strat_test_set[\"income_cat\"].value_counts() / len(strat_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff841cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = strat_train_set.copy()\n",
    "housing.plot(kind=\"scatter\", \n",
    "             x=\"longitude\", \n",
    "             y=\"latitude\", \n",
    "             alpha=0.4, \n",
    "             s=housing[\"population\"]/100, \n",
    "             label=\"population\", \n",
    "             figsize=(10, 7),\n",
    "             c=\"median_house_value\", \n",
    "             cmap=plt.get_cmap(\"jet\"),\n",
    "             colorbar=True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4117a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = housing.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5539a87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f8ee09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "attributes = [\"median_house_value\", \"median_income\", \"total_rooms\", \"housing_median_age\"]\n",
    "scatter_matrix(housing[attributes], figsize=(12, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e282ce8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.plot(kind=\"scatter\", x=\"median_income\", y=\"median_house_value\", alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285501fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"rooms_per_household\"] = housing[\"total_rooms\"]/housing[\"households\"]\n",
    "housing[\"bedrooms_per_room\"] = housing[\"total_bedrooms\"]/housing[\"total_rooms\"]\n",
    "housing[\"population_per_household\"] = housing[\"population\"]/housing[\"households\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dc71f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = housing.corr()\n",
    "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c3bb886e",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26ee2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = strat_train_set.drop(\"median_house_value\", axis=1)\n",
    "housing_labels = strat_train_set[\"median_house_value\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e300df82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "housing_num = housing.drop(\"ocean_proximity\", axis=1)\n",
    "imputer.fit(housing_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73899e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer.statistics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2a1d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_num.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2077ac4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = imputer.transform(housing_num) # imputes all missing values in housing_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a56c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_tr = pd.DataFrame(X, columns=housing_num.columns)\n",
    "housing_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26f7a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(housing[[\"ocean_proximity\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fa7145",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(housing[\"ocean_proximity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af24458",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_cat = housing[[\"ocean_proximity\"]]\n",
    "housing_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d262869f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "\n",
    "housing_cat_encoded = ordinal_encoder.fit_transform(housing_cat)\n",
    "housing_cat_encoded[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8500264",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b66646",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "cat_encoder = OneHotEncoder()\n",
    "housing_cat_1hot = cat_encoder.fit_transform(housing_cat)\n",
    "housing_cat_1hot.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028fb111",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_encoder.categories_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5fed698d",
   "metadata": {},
   "source": [
    "### Adding Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8886abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "rooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6 # column index\n",
    "\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedrooms_per_room=True):\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, households_ix] \n",
    "        population_per_household = X[:, population_ix] / X[:, households_ix] \n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household, population_per_household]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "caed74c5",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "\n",
    "`X[:, rooms_ix]` Extract a specific column from a two-dimensional array or matrix .\n",
    "\n",
    "`np.c_` concatenates arrays along the second axis. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec5d22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_example = np.array([[1, 2],\n",
    "              [3, 4],\n",
    "              [5, 6]])\n",
    "X_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3347b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "rooms_per_household_example = np.array([7, 8, 9])\n",
    "np.c_[X_example, rooms_per_household_example]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9f5519",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    ('attribs_adder', CombinedAttributesAdder()),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "housing_num_tr = num_pipeline.fit_transform(housing_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20da3828",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_attribs = list(housing_num)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_attribs),\n",
    "    (\"cat\", OneHotEncoder(), cat_attribs),\n",
    "])\n",
    "\n",
    "housing_prepared = full_pipeline.fit_transform(housing)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4cb307b9",
   "metadata": {},
   "source": [
    "## Training a Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3781a1ac",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1459a306",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5868475",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_data = housing.iloc[:5]\n",
    "example_labels = housing_labels.iloc[:5]\n",
    "example_data_prepared = full_pipeline.transform(example_data)\n",
    "print(\"Predictions:\", lin_reg.predict(example_data_prepared))\n",
    "print(\"Labels:\", list(example_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e928438e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "housing_predictions = lin_reg.predict(housing_prepared)\n",
    "lin_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse) # RMSE is a typical performance measure for regression problems\n",
    "lin_rmse\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0dfba79c",
   "metadata": {},
   "source": [
    "Since the price of houses for most houses ranges between $120,000 and $250,000, an error of $67,520 is not a great result. This is an example of **underfitting**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0800c3bc",
   "metadata": {},
   "source": [
    "### Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0fb3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47389802",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_predictions = tree_reg.predict(housing_prepared)\n",
    "tree_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_rmse"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68841b7a",
   "metadata": {},
   "source": [
    "The error is 0.0, which means that the model has badly overfit the data. We didn't split the data into train and test sets. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a6f627ac",
   "metadata": {},
   "source": [
    "### Cross-Validation\n",
    "\n",
    "`cross_val_score` function automates this process by taking care of splitting the data, training the model, and evaluating its performance.\n",
    "\n",
    "The following code randomly splits the training set into 10 distinct subsets called folds, then it trains and evaluates the Decision Tree model 10 times.\n",
    "\n",
    "The result is an array containing the 10 evaluation scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b9c4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# 10-fold cross-validation\n",
    "scores = cross_val_score(tree_reg, \n",
    "                         housing_prepared, \n",
    "                         housing_labels, \n",
    "                         scoring=\"neg_mean_squared_error\", \n",
    "                         cv=10) \n",
    "\n",
    "tree_rmse_scores = np.sqrt(-scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d376becf",
   "metadata": {},
   "source": [
    "By convention, most scoring functions in `scikit-learn` are designed so that higher values indicate better performance. However, **in the case of the mean squared error, lower values indicate better performance** because the goal is to minimize the error. \n",
    "\n",
    "To align with the convention of higher scores indicating better performance, the negation of the mean squared error is used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436add74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "display_scores(tree_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53531fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression scores\n",
    "lin_scores = cross_val_score(lin_reg, \n",
    "                             housing_prepared, \n",
    "                             housing_labels, \n",
    "                             scoring=\"neg_mean_squared_error\", \n",
    "                             cv=10)\n",
    "\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a7ec91cf",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97b30cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = RandomForestRegressor()\n",
    "forest_reg.fit(housing_prepared, housing_labels)\n",
    "housing_predictions = forest_reg.predict(housing_prepared)\n",
    "forest_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "forest_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9691fa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_scores(forest_rmse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e24dc7f3",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d46a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(forest_mse, \"forest_mse.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73622841",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_mse_loaded = joblib.load(\"forest_mse.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9e203d",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_rmse_loaded = np.sqrt(forest_mse_loaded)\n",
    "forest_rmse_loaded"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9b54b11a",
   "metadata": {},
   "source": [
    "## Model Fine-Tuning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff23fa65",
   "metadata": {},
   "source": [
    "### Grid Search\n",
    "Searches for the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc64cc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]}, \n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "    ]\n",
    "\n",
    "forest_reg = RandomForestRegressor()\n",
    "\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
    "                            scoring='neg_mean_squared_error',\n",
    "                            return_train_score=True)\n",
    "\n",
    "grid_search.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a56cb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502c6f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef380c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be2f1770",
   "metadata": {},
   "source": [
    "### Analyze the Best Models and Their Errors\n",
    "\n",
    "`RandomForestRegressor` can indicate the relative importance of each attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40101b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38acc976",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_attribs = [\"rooms_per_hhold\", \"pop_per_hhold\", \"bedrooms_per_room\"]\n",
    "cat_encoder = full_pipeline.named_transformers_[\"cat\"]\n",
    "cat_one_hot_attribs = list(cat_encoder.categories_[0])\n",
    "attributes = num_attribs + extra_attribs + cat_one_hot_attribs\n",
    "sorted(zip(feature_importances, attributes), reverse=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d6f55011",
   "metadata": {},
   "source": [
    "### Evaluating on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65396f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = grid_search.best_estimator_\n",
    "\n",
    "X_test = strat_test_set.drop(\"median_house_value\", axis=1)\n",
    "y_test = strat_test_set[\"median_house_value\"].copy()\n",
    "\n",
    "X_test_prepared = full_pipeline.transform(X_test)\n",
    "\n",
    "final_predictions = final_model.predict(X_test_prepared)\n",
    "\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "final_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdd1e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "confindence = 0.95\n",
    "squared_errors = (final_predictions - y_test) ** 2\n",
    "np.sqrt(stats.t.interval(confindence, len(squared_errors) - 1,\n",
    "                            loc=squared_errors.mean(),\n",
    "                            scale=stats.sem(squared_errors)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aafe337d",
   "metadata": {},
   "source": [
    "### Support Vector Machine Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d8977a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "SVM_reg = SVR()\n",
    "param_grid = [\n",
    "        {'kernel': ['linear'], 'C': [10., 30., 100., 300., 1000., 3000., 10000., 30000.0]},\n",
    "        {'kernel': ['rbf'], 'C': [1.0, 3.0, 10., 30., 100., 300., 1000.0],\n",
    "         'gamma': [0.01, 0.03, 0.1, 0.3, 1.0, 3.0]},\n",
    "    ]\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(SVM_reg, param_grid, cv=5,\n",
    "                            scoring='neg_mean_squared_error',\n",
    "                            verbose=2)\n",
    "grid_search.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3223f535",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703cc84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_mse = grid_search.best_score_\n",
    "rmse = np.sqrt(-negative_mse)\n",
    "rmse"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "94371c1c",
   "metadata": {},
   "source": [
    "### Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5cb027",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import expon, reciprocal\n",
    "\n",
    "SVM_reg = SVR()\n",
    "\n",
    "param_distribs = {\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'C': reciprocal(20, 200000),\n",
    "        'gamma': expon(scale=1.0),\n",
    "    }\n",
    "randomized_search = RandomizedSearchCV(SVM_reg, param_distributions=param_distribs,\n",
    "                                n_iter=50, cv=5, scoring='neg_mean_squared_error',\n",
    "                                verbose=2, random_state=42)\n",
    "randomized_search.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf54a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "randomized_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b102135",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_mse = randomized_search.best_score_\n",
    "rmse = np.sqrt(-negative_mse)\n",
    "rmse"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1947b236",
   "metadata": {},
   "source": [
    "### Adding a Transformer in the Preparation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca3c353",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "def indices_of_top_k(arr, k):\n",
    "    return np.sort(np.argpartition(np.array(arr), -k)[-k:])\n",
    "\n",
    "class TopFeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, feature_importances, k):\n",
    "        self.feature_importances = feature_importances\n",
    "        self.k = k\n",
    "    def fit(self, X, y=None):\n",
    "        self.feature_indices_ = indices_of_top_k(self.feature_importances, self.k)\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[:, self.feature_indices_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6babf9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "pipeline = Pipeline([\n",
    "    ('preparation', full_pipeline), \n",
    "    ('feature_selection', TopFeatureSelector(feature_importances, k))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2942c64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_prepared_top_k_features = pipeline.fit_transform(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0c2447",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_prepared_top_k_features[0:3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19745cb8",
   "metadata": {},
   "source": [
    "## Final Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0cf9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('preparation', full_pipeline), \n",
    "    ('feature_selection', TopFeatureSelector(feature_importances, k)),\n",
    "    ('SVM_reg', SVR(**randomized_search.best_params_))\n",
    "])\n",
    "\n",
    "pipeline.fit(housing, housing_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e28988e",
   "metadata": {},
   "source": [
    "Note: The double asterisks (**) are used to unpack the dictionary and pass its contents as keyword arguments to the SVR estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd0f463",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afe6ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = housing.iloc[:4]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730b9482",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = housing_labels.iloc[:4]\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07676ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predictions:\\t\", pipeline.predict(data))\n",
    "print(\"Labels:\\t\\t\", list(labels))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
